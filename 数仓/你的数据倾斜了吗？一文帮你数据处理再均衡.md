# 你的数据倾斜了吗？一文帮你数据处理再均衡
此篇主要总结到 Hive,Flink,Spark 出现数据倾斜的表现，原因和解决办法。首先会让大家认识到不同框架或者计算引擎处理倾斜的方案。最后你会发现计算框架只是 “异曲”，文末总结才是 “同工之妙”。点击收藏与分享，工作和涨薪用得到！！！

## 数据倾斜

数据倾斜最笼统概念就是数据的分布不平衡，有些地方数据多，有些地方数据少。在计算过程中有些地方数据早早地处理完了，有些地方数据迟迟没有处理完成，造成整个处理流程迟迟没有结束，这就是最直接数据倾斜的表现。

## Hive

![](https://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dRcs6oxPLKSueaox2h9sLQjwKN9hvqic6nNpU8PszKngoy066L9WecF6PdbEbiaE8JicqRfCsSlicicv5Q/640?wx_fmt=png)

### Hive 数据倾斜表现

就是单说 hive 自身的 MR 引擎：发现所有的 map task 全部完成，并且 99% 的 reduce task 完成，只剩下一个或者少数几个 reduce task 一直在执行，这种情况下一般都是发生了数据倾斜。说白了就是 Hive 的数据倾斜本质上是 MapReduce 的数据倾斜。

### Hive 数据倾斜的原因

在 MapReduce 编程模型中十分常见，大量相同的 key 被分配到一个 reduce 里，造成一个 reduce 任务累死，其他 reduce 任务闲死。查看任务进度，发现长时间停留在 99% 或 100%，查看任务监控界面，只有少量的 reduce 子任务未完成。

1.  key 分布不均衡。
2.  业务问题或者业务数据本身的问题，某些数据比较集中。

-   join 小表：其中一个表是小表，但是 key 比较集中，导致的就是某些 Reduce 的值偏高。
-   空值或无意义值：如果缺失的项很多，在做 join 时这些空值就会非常集中，拖累进度。
-   group by：维度过小。
-   distinct：导致最终只有一个 Reduce 任务。

### Hive 数据倾斜解决

1.  group by 代替 distinct 要统计某一列的去重数时，如果数据量很大，count(distinct) 就会非常慢，原因与 order by 类似，count(distinct) 逻辑导致最终只有一个 Reduce 任务。
2.  对 1 再优化：group by 配置调整

-   map 端预聚合

    group by 时，combiner 在 map 端做部分预聚合，可以有效减少 shuffle 数据量。

    checkinterval：设置 map 端预聚合的行数阈值，超过该值就会分拆 job。

`hive.map.aggr=true // 默认  
hive.groupby.mapaggr.checkinterval=100000 // 默认  
`

-   倾斜均衡配置 Hive 自带了一个均衡数据倾斜的配置项。

    其实现方法是在 group by 时启动两个 MR job。第一个 job 会将 map 端数据随机输入 reducer，每个 reducer 做部分聚合，相同的 key 就会分布在不同的 reducer 中。第二个 job 再将前面预处理过的数据按 key 聚合并输出结果，这样就起到了均衡的效果。

`hive.groupby.skewindata=false // 默认  
`

3.  join 基础优化

-   Hive 在解析带 join 的 SQL 语句时，会默认将最后一个表作为大表，将前面的表作为小表，将它们读进内存。如果表顺序写反，如果大表在前面，引发 OOM。不过现在 hive 自带优化。
-   map join: 特别适合大小表 join 的情况，大小表 join 在 map 端直接完成 join 过程，没有 reduce，效率很高。
-   多表 join 时 key 相同：会将多个 join 合并为一个 MR job 来处理，两个 join 的条件不相同，就会拆成多个 MR job 计算。

4.  sort by 代替 order by

    将结果按某字段全局排序，这会导致所有 map 端数据都进入一个 reducer 中，在数据量大时可能会长时间计算不完。使用 sort by，那么还是会视情况启动多个 reducer 进行排序，并且保证每个 reducer 内局部有序。为了控制 map 端数据分配到 reducer 的 key，往往还要配合 distribute by 一同使用。如果不加 distribute by 的话，map 端数据就会随机分配到 reducer。
5.  单独处理倾斜 key

    一般来讲倾斜的 key 都很少，我们可以将它们抽样出来，对应的行单独存入临时表中，然后打上随机数前缀，最后再进行聚合。或者是先对 key 做一层 hash，先将数据随机打散让它的并行度变大，再汇集。其实办法一样。

## Flink

![](https://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dRcs6oxPLKSueaox2h9sLQjFwpQIMic5eQgcYYacatdtsz4rq9w9eJjasUqgKoS0EQMDxSW0kl6icQg/640?wx_fmt=png)

### Flink 数据倾斜的表现

1.  Flink 任务出现数据倾斜的直观表现是任务节点频繁出现反压。
2.  部分节点出现 OOM 异常，是因为大量的数据集中在某个节点上，导致该节点内存被爆，任务失败重启。

### Flink 数据倾斜的原因

1.  代码 KeyBy、GroupBy 等操作，错误的使用了分组 Key，产生数据热点。
2.  业务上有严重的数据热点。

### Flink 如何定位数据倾斜

1.  定位反压

Flink Web UI 自带的反压监控（直接方式）、Flink Task Metrics（间接方式）。通过监控反压的信息，可以获取到数据处理瓶颈的 Subtask。

2.  确定数据倾斜

Flink Web UI 自带 Subtask 接收和发送的数据量。当 Subtasks 之间处理的数据量有较大的差距，则该 Subtask 出现数据倾斜。

### Flink 数据倾斜的处理

1.  数据源 source 消费不均匀

通过调整 Flink 并行度，解决数据源消费不均匀或者数据源反压的情况。我们常常例如 kafka 数据源，调整并行度的原则：Source 并行度与 kafka 分区数是一样的，或者 kafka 分区数是 KafkaSource 并发度的整数倍。建议是并行度等于分区数。

2.  key 分布不均匀

上游数据分布不均匀，使用 keyBy 来打散数据的时候出现倾斜。通过添加随机前缀，打散 key 的分布，使得数据不会集中在几个 Subtask。

3.  两阶段聚合解决 KeyBy（加盐局部聚合 + 去盐全局聚合）

预聚合：加盐局部聚合，在原来的 key 上加随机的前缀或者后缀。

聚合：去盐全局聚合，删除预聚合添加的前缀或者后缀，然后进行聚合统计。

## Spark

![](https://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dRcs6oxPLKSueaox2h9sLQjIGVQ5icUMpzdyLDLLVUUzzvPLorNvfF35Z2ryMhAic6PW8Bz7I8TwicIQ/640?wx_fmt=png)

### Spark 数据倾斜的表现

1.  Executor lost，OOM，Shuffle 过程出错。
2.  Driver OOM。
3.  单个 Executor 执行时间特别久，整体任务卡在某个阶段不能结束。
4.  正常运行的任务突然失败。

### Spark 定位数据倾斜

Spark 数据倾斜只会发生在 shuffle 过程中。

这里给大家罗列一些常用的并且可能会触发 shuffle 操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition 等。

出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。

### Spark 数据倾斜的解决方案

#### 使用 Hive ETL 预处理数据

通过 Hive 来进行数据预处理（即通过 Hive ETL 预先对数据按照 key 进行聚合，或者是预先和其他表进行 join），然后在 Spark 作业中针对的数据源就不是原来的 Hive 表了，而是预处理后的 Hive 表。此时由于数据已经预先进行过聚合或 join 操作了，那么在 Spark 作业中也就不需要使用原先的 shuffle 类算子执行这类操作了。

###### 适合场景

导致数据倾斜的是 Hive 表。如果该 Hive 表中的数据本身很不均匀（比如某个 key 对应了 100 万数据，其他 key 才对应了 10 条数据），而且业务场景需要频繁使用 Spark 对 Hive 表执行某个分析操作，那么比较适合使用这种技术方案。

#### 过滤少数导致倾斜的 key

如果我们判断那少数几个数据量特别多的 key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个 key。

###### 适合场景

如果发现导致倾斜的 key 就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如 99% 的 key 就对应 10 条数据，但是只有一个 key 对应了 100 万数据，从而导致了数据倾斜。

#### 提高 shuffle 操作的并行度

增加 shuffle read task 的数量，可以让原本分配给一个 task 的多个 key 分配给多个 task，从而让每个 task 处理比原来更少的数据。

#### 两阶段聚合（加盐局部聚合 + 去盐全局聚合）

预聚合：加盐局部聚合，在原来的 key 上加随机的前缀或者后缀。

聚合：去盐全局聚合，删除预聚合添加的前缀或者后缀，然后进行聚合统计。

###### 适合场景

对 RDD 执行 reduceByKey 等聚合类 shuffle 算子或者在 Spark SQL 中使用 group by 语句进行分组聚合时，比较适用这种方案。

#### 将 reduce join 转为 map join

使用 Broadcast 变量与 map 类算子实现 join 操作，进而完全规避掉 shuffle 类的操作，彻底避免数据倾斜的发生和出现。

###### 适合场景

在对 RDD 使用 join 类操作，或者是在 Spark SQL 中使用 join 语句时，而且 join 操作中的一个 RDD 或表的数据量比较小，比较适用此方案。

#### 采样倾斜 key 并分拆 join 操作

对 join 导致的倾斜是因为某几个 key，可将原本 RDD 中的倾斜 key 拆分出原 RDD 得到新 RDD，并以加随机前缀的方式打散 n 份做 join，将倾斜 key 对应的大量数据分摊到更多 task 上来规避倾斜。

###### 适合场景

两个较大的 RDD/Hive 表进行 join 时，且一个 RDD/Hive 表中少数 key 数据量过大，另一个 RDD/Hive 表的 key 分布较均匀（RDD 中两者之一有一个更倾斜）。

#### 用随机前缀和扩容 RDD 进行 join

查看 RDD/Hive 表中的数据分布情况，找到那个造成数据倾斜的 RDD/Hive 表，比如有多个 key 都对应了超过 1 万条数据。然后将该 RDD 的每条数据都打上一个 n 以内的随机前缀。同时对另外一个正常的 RDD 进行扩容，将每条数据都扩容成 n 条数据，扩容出来的每条数据都依次打上一个 0~n 的前缀。

###### 适合场景

RDD 中有大量 key 导致倾斜。

## 总结

不管再出现分布式计算框架出现数据倾斜问题解决思路如下：很多数据倾斜的问题，都可以用和平台无关的方式解决，比如更好的数据预处理，异常值的过滤等。因此，解决数据倾斜的重点在于对数据设计和业务的理解，这两个搞清楚了，数据倾斜就解决了大部分了。关注这几个方面：

1.  业务逻辑方面

数据预处理。

解决热点数据：分而治之 (第一次打散计算，第二次再最终聚合计算)。

4.  程序代码层面

    导致最终只有一个 Reduce 任务的，需要想到用替代的关键字或者算子去提升 Reduce 任务数。

    调参。

3. 熟悉自己手中的工具（框架），优秀的框架已经负重前行给你优化了好多。

    不仅要学，更学会去用，更要努力去完善拓展框架功能。  

## 我要去大厂专题 往期回顾

[Flink 吐血总结，学习与面试收藏这一篇就够了！！！](http://mp.weixin.qq.com/s?__biz=MzI4MjU4MzkwOQ==&mid=2247484713&idx=1&sn=b1c6fb7cedcfbfa6fb22d2e02e8b375c&chksm=eb96f323dce17a35fb5f81996199cffb0a1d6797be3feae3ccc61d051a0f9acd88fd07535276&scene=21#wechat_redirect)

[Kafka 面试准备，收藏这一篇就够了！！！](http://mp.weixin.qq.com/s?__biz=MzI4MjU4MzkwOQ==&mid=2247484677&idx=1&sn=00ce05f7cb76cad7af960e47172154f4&chksm=eb96f30fdce17a191919b43e99893d15e3f04017681d64aa09e6c7a6d8108ccd2e051fafff7e&scene=21#wechat_redirect)  

[查询引擎怎么选？7000 字解析所有开源引擎的秘密](http://mp.weixin.qq.com/s?__biz=MzI4MjU4MzkwOQ==&mid=2247484635&idx=1&sn=17436dd8178800fe0d2e2e2cb1768a7a&chksm=eb96f2d1dce17bc7279c457551a682382b9d10f3bbafac5ee66a72d1d5e505b2338fc6f9e8bb&scene=21#wechat_redirect)  

[大数据调度系统选得好, 下班回家早; 调度用得对, 半夜安心睡](http://mp.weixin.qq.com/s?__biz=MzI4MjU4MzkwOQ==&mid=2247484632&idx=1&sn=c99cb782ed0a2f3c82d6f92478a55aa5&chksm=eb96f2d2dce17bc464e9d1c2a84b95f024aec2f97e7f1da05848c57923d320e95640b5a08e7e&scene=21#wechat_redirect)  

[六千字总结: 大数据框架 (分区，分桶，分片), 建议收藏](http://mp.weixin.qq.com/s?__biz=MzI4MjU4MzkwOQ==&mid=2247484600&idx=1&sn=53420bb2919e200e95fd320e37b7b487&chksm=eb96f2b2dce17ba48b6857af63ba70a91a12f8b12d5a106a58c32b58367449b6f67de601ab9f&scene=21#wechat_redirect)  

同学共进，点赞，转发，在看，关注，是我学习之动力。

和我联系吧，交流大数据知识, 一起成长\~\~~ 
 [https://mp.weixin.qq.com/s/yeyKvL8s7u-EDw1Ab8i9ZQ](https://mp.weixin.qq.com/s/yeyKvL8s7u-EDw1Ab8i9ZQ)
