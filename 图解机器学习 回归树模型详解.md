# 图解机器学习 | 回归树模型详解
引言
--

大家在前面的部分学习到了使用决策树进行分类，实际决策树也可以用作回归任务，我们叫作回归树。而回归树的结构还是树形结构，但是属性选择与生长方式和分类的决策树有不同，我们一起来看看它的原理知识吧。

（本篇回归树模型部分内容涉及到机器学习基础知识、决策树算法，没有先序知识储备的宝宝可以查看ShowMeAI的文章 [图解机器学习 | **机器学习基础知识**](https://www.showmeai.tech/article-detail/185) 及 [**决策树模型详解**](https://www.showmeai.tech/article-detail/190)）。

1.决策树回归算法核心思想
-------------

### 1）决策树结构回顾

我们一起来回顾一下决策树的结构，**决策树的典型结构如下图所示**。

![](https://img-blog.csdnimg.cn/img_convert/df31eaa5086e76e9e6010ef336d7b024.png)

决策树的**学习过程**和**预测过程**如下图所示。详细内容可以参考ShowMeAI的文章 [**决策树模型详解**](https://www.showmeai.tech/article-detail/190)。

![](https://img-blog.csdnimg.cn/img_convert/57b635ae49b0a5892f76a19eaf7a002f.png)

**主流的决策树算法有**：

*   **ID3**：基于**信息增益**来选择分裂属性（每步选择信息增益最大的属性作为分裂节点，树可能是多叉的）。
*   **C4.5**：基于**信息增益率**来选择分裂属性（每步选择信息增益率最大的属性作为分裂节点，树可能是多叉的）。
*   **CART**：基于**基尼系数**来构建决策树（每步要求基尼系数最小，树是二叉的）。
    *   其中：CART树全称Classification And Regression Tree，即可以用于分类，也可以用于回归，这里指的回归树就是 CART 树，ID3和C4.5不能用于回归问题。

### 2）回归树的核心思想

要讲回归树，我们一定会提到CART树，**CART树全称Classification And Regression Trees，包括分类树与回归树**。

**CART的特点是**：假设决策树是二叉树，内部结点特征的取值为「是」和「否」，右分支是取值为「是」的分支，左分支是取值为「否」的分支。这样的决策树等价于「递归地二分每个特征」，将输入空间（特征空间）划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。

设有数据集 *D* ，构建回归树的大体思路如下：

回归树构建完成后，就完成了对整个输入空间的划分（即完成了回归树的建立）。将整个输入空间划分为多个子区域，每个子区域输出为该区域内所有训练样本的平均值。

![](https://img-blog.csdnimg.cn/img_convert/f89e002cdfd77b12f6a503f09d6cb08f.png)

![](https://img-blog.csdnimg.cn/img_convert/f77d687a526e9793f1e2894c9e265987.png)

我们知道了回归树其实是将输入空间划分为 ![](https://www.zhihu.com/equation?tex=M)个单元，每个区域的输出值是该区域内所有点 ![](https://www.zhihu.com/equation?tex=y)值的平均数。但我们希望构建最有效的回归树：预测值与真实值差异度最小。下面部分我们展开讲讲，回归树是如何生长的。

2.启发式切分与最优属性选择
--------------

### 1）回归树模型示例

我们用一个经典的棒球案例来解释回归树：根据从业年限和表现，去预估棒球运动员的工资。如下所示，有 1987 个数据样本，包含 322 个棒球运动员。

*   **红黄**表示高收入，**蓝绿**表示低收入。
*   **横坐标**是年限，**纵坐标**是表现。

![](https://img-blog.csdnimg.cn/img_convert/071b3c0c9f90fa59e40e1eaed0e2f02f.png)

这个简单案例中，每个样本数据有两个特征：**从业年限** ![](https://www.zhihu.com/equation?tex=Years)**和成绩表现** ![](https://www.zhihu.com/equation?tex=Hits)，回归树的决策过程由最终生成的回归树决定，如右图所示：

![](https://img-blog.csdnimg.cn/img_convert/1cc0c6ed994b7dd746679d670f2d9907.png)

我们来深入拆解和对应一下，其实回归树构建完成后，实现了对整个空间的划分（如下图所示）。实际预测时，新样本会按照回归树的决策过程，被划分到下图 ![](https://www.zhihu.com/equation?tex=R_1)、![](https://www.zhihu.com/equation?tex=R_2)、![](https://www.zhihu.com/equation?tex=R_3)之中的一个区域 ![](https://www.zhihu.com/equation?tex=R_i)，而这个新样本的预测值（本案例中为棒球运动员的工资)就是它所在的区域。

*   ![](https://www.zhihu.com/equation?tex=R_i)中所有训练样本的工资平均值。

![](https://img-blog.csdnimg.cn/img_convert/ff3200f413de7b4a82880bc18a779e37.png)

回归树背后的含义：对空间的划分。整个平面被划分成 3 部分：

![](https://www.zhihu.com/equation?tex=R1%20%3D%20%7BX%20%7CYears%20%3C%204.5%7D)

![](https://www.zhihu.com/equation?tex=R2%20%3D%20%7BX%20%7CYears%20%E2%89%A5%204.5%2C%20Hits%20%3C%20117.5%7D)

![](https://www.zhihu.com/equation?tex=R3%20%3D%20%7BX%20%7CYears%20%E2%89%A5%204.5%2C%20Hits%20%E2%89%A5%20117.5%7D)

### 2）回归树构建方法

下面切到回归树构建的核心：切分方式与属性选择。

假设一回归问题，预估结果 ![](https://www.zhihu.com/equation?tex=y%20%5Cin%20R)，特征向量为 ![](https://www.zhihu.com/equation?tex=X%20%3D%20%5Bx_1%2Cx_2%2Cx_3%2C%20%5Cdots%20%2C%20x_p%20%5D)，回归树 2 个步骤是：

仔细观察一下上面的过程，实际上我们希望能找到如下的 RSS 最小的化划分方式 ![](https://www.zhihu.com/equation?tex=R_1%2CR_2%2CR_3%2C%20%5Cdots%20%2CR_J)

![](https://www.zhihu.com/equation?tex=R%20S%20S%3D%5Csum_%7Bj%3D1%7D%5E%7BJ%7D%20%5Csum_%7Bi%20%5Cin%20R%20j%7D%5Cleft%28y_%7Bi%7D-%5Ctilde%7By%7D_%7BR_%7Bj%7D%7D%5Cright%29%5E%7B2%7D)

![](https://img-blog.csdnimg.cn/img_convert/5fe22ee9ae6d4547eb723fcea931ad98.png)

但是这个最小化和探索的过程，计算量是非常非常大的。我们采用「探索式的递归二分」来尝试解决这个问题。

#### 递归二分

回归树采用的是「自顶向下的贪婪式递归方案」。这里的贪婪，指的是每一次的划分，只考虑当前最优，而不回头考虑之前的划分。从数学上定义，即选择切分的维度（特征） ![](https://www.zhihu.com/equation?tex=x_j)以及切分点 ![](https://www.zhihu.com/equation?tex=s)使得划分后的树RSS结果最小，公式如下所示：

![](https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D%20%26%20R_%7B1%7D%28j%2C%20s%29%3D%5Cleft%5C%7Bx%20%5Cmid%20x_%7Bj%7D%3Cs%5Cright%5C%7D%20%5C%5C%20%26%20R_%7B2%7D%28j%2C%20s%29%3D%5Cleft%5C%7Bx%20%5Cmid%20x_%7Bj%7D%20%5Cgeq%20s%5Cright%5C%7D%20%5C%5C%20%26%20RSS%3D%5Csum%20x_%7Bi%7D%20%5Cin%20R_%7B1%7D%28j%2C%20s%29%5Cleft%28y_%7Bi%7D-%5Ctilde%7By%7D_%7BR%201%7D%5Cright%29%5E%7B2%7D%2B%5Csum%20x_%7Bi%7D%20%5Cin%20R_%7B2%7D%28j%2C%20s%29%5Cleft%28y_%7Bi%7D-%5Ctilde%7By%7D_%7BR_%7B2%7D%7D%5Cright%29%5E%7B2%7D%20%5Cend%7Baligned%7D)

![](https://img-blog.csdnimg.cn/img_convert/72cd8b32643bb1a97ff9aac28078f35e.png)

我们再来看看「**递归切分**」。下方有两个对比图，其中左图是非递归方式切分得到的，而右图是二分递归的方式切分得到的空间划分结果（下一次划分一定是在之前的划分基础上将某个区域一份为二）。

![](https://img-blog.csdnimg.cn/img_convert/24d3c352b173c64bcd0dbdf16508da31.png)

**两种方式的差别是**：递归切分一定可以找到一个较优的解，非递归切分穷举不了所有情况，算法上无法实现，可能无法得到一个较好的解。

![](https://img-blog.csdnimg.cn/img_convert/ed0edc942f3390d956862c0551962122.png)

**回归树总体流程类似于分类树**：分枝时穷举每一个特征可能的划分阈值，来寻找最优切分特征和最优切分点阈值，衡量的方法是平方误差最小化。分枝直到达到预设的终止条件（如叶子个数上限）就停止。

但通常在处理具体问题时，单一的回归树模型能力有限且有可能陷入过拟合，我们经常会利用集成学习中的Boosting思想，对回归树进行增强，得到的新模型就是提升树（Boosting Decision Tree），进一步，可以得到[**梯度提升树**（Gradient Boosting Decision Tree，GBDT）](https://www.showmeai.tech/article-detail/193)，再进一步可以升级到[**XGBoost**](https://www.showmeai.tech/article-detail/194)。通过多棵回归树拟合残差，不断减小预测值与标签值的偏差，从而达到精准预测的目的，ShowMeAI会在后面介绍这些高级算法。

3.过拟合与正则化
---------

### 1）过拟合问题

决策树模型存在过拟合风险，通常情况下，树的规模太小会导致模型效果不佳，而树的规模太大就会造成过拟合，非常难以控制。

### 2）过拟合问题处理

对于决策树，我们通常有如下一些策略可以用于环节过拟合：

![](https://img-blog.csdnimg.cn/img_convert/623a660df48c80480e5c1002ad4e4436.png)

#### （1）约束控制树的过度生长

*   **限制树的深度**：当达到设置好的最大深度时结束树的生长。
*   **分类误差法**：当树继续生长无法得到客观的分类误差减小，就停止生长。
*   **叶子节点最小数据量限制**：一个叶子节点的数据量过小，树停止生长。

#### （2）剪枝

约束树生长的缺点就是提前扼杀了其他可能性，过早地终止了树的生长，我们也可以等待树生长完成以后再进行剪枝，即所谓的后剪枝，而后剪枝算法主要有以下几种：

*   Reduced-Error Pruning（REP，错误率降低剪枝）。
*   Pesimistic-Error Pruning（PEP，悲观错误剪枝）。
*   Cost-Complexity Pruning（CCP，代价复杂度剪枝）。
*   Error-Based Pruning（EBP，基于错误的剪枝）。

### 3）正则化

对于回归树而言，在剪枝过程中我们会添加正则化项衡量。如下所示，考虑剪枝后得到的子树 ![](https://www.zhihu.com/equation?tex=%5Cleft%20%5C%7BT_a%20%5Cright%20%5C%7D)
，其中 ![](https://www.zhihu.com/equation?tex=%5Calpha)是正则化项的系数。当固定住 ![](https://www.zhihu.com/equation?tex=%5Calpha)之后，最佳的 ![](https://www.zhihu.com/equation?tex=T_a)就是使得下列式子值最小的子树。

![](https://www.zhihu.com/equation?tex=%5Csum_%7Bm%3D1%7D%5E%7B%7CT%7C%7D%20%5Csum_%7Bx_%7Bi%7D%20%5Cin%20R_%7Bm%7D%7D%5Cleft%28y_%7Bi%7D-%5Ctilde%7By%7D_%7BR_%7B2%7D%7D%5Cright%29%5E%7B2%7D%2B%5Calpha%7CT%7C)

更多监督学习的算法模型总结可以查看ShowMeAI的文章 [AI知识技能速查 | **机器学习-监督学习**](https://www.showmeai.tech/article-detail/113)。

* * *

视频教程
----

可以点击 [**B站**](https://www.bilibili.com/video/BV1y44y187wN?p=12) 查看视频的【双语字幕】版本

[https://www.bilibili.com/video/BV1y44y187wN?p=12](https://www.bilibili.com/video/BV1y44y187wN?p=12)

机器学习【算法】系列教程
------------

*   [图解机器学习 | 机器学习基础知识](https://www.showmeai.tech/article-detail/185)
*   [图解机器学习 | 模型评估方法与准则](https://www.showmeai.tech/article-detail/186)
*   [图解机器学习 | KNN算法及其应用](https://www.showmeai.tech/article-detail/187)
*   [图解机器学习 | 逻辑回归算法详解](https://www.showmeai.tech/article-detail/188)
*   [图解机器学习 | 朴素贝叶斯算法详解](https://www.showmeai.tech/article-detail/189)
*   [图解机器学习 | 决策树模型详解](https://www.showmeai.tech/article-detail/190)
*   [图解机器学习 | 随机森林分类模型详解](https://www.showmeai.tech/article-detail/191)
*   [图解机器学习 | 回归树模型详解](https://www.showmeai.tech/article-detail/192)
*   [图解机器学习 | GBDT模型详解](https://www.showmeai.tech/article-detail/193)
*   [图解机器学习 | XGBoost模型最全解析](https://www.showmeai.tech/article-detail/194)
*   [图解机器学习 | LightGBM模型详解](https://www.showmeai.tech/article-detail/195)
*   [图解机器学习 | 支持向量机模型详解](https://www.showmeai.tech/article-detail/196)
*   [图解机器学习 | 聚类算法详解](https://www.showmeai.tech/article-detail/197)
*   [图解机器学习 | PCA降维算法详解](https://www.showmeai.tech/article-detail/198)

机器学习【实战】系列教程
------------

*   [机器学习实战 | Python机器学习算法应用实践](https://www.showmeai.tech/article-detail/201)
*   [机器学习实战 | SKLearn入门与简单应用案例](https://www.showmeai.tech/article-detail/202)
*   [机器学习实战 | SKLearn最全应用指南](https://www.showmeai.tech/article-detail/203)
*   [机器学习实战 | XGBoost建模应用详解](https://www.showmeai.tech/article-detail/204)
*   [机器学习实战 | LightGBM建模应用详解](https://www.showmeai.tech/article-detail/205)
*   [机器学习实战 | Python机器学习综合项目-电商销量预估](https://www.showmeai.tech/article-detail/206)
*   [机器学习实战 | Python机器学习综合项目-电商销量预估<进阶方案>](https://www.showmeai.tech/article-detail/207)
*   [机器学习实战 | 机器学习特征工程最全解读](https://www.showmeai.tech/article-detail/208)
*   [机器学习实战 | 自动化特征工程工具Featuretools应用](https://www.showmeai.tech/article-detail/209)
*   [机器学习实战 | AutoML自动化机器学习建模](https://www.showmeai.tech/article-detail/210)

[ShowMeAI](https://www.showmeai.tech/) 系列教程推荐
---------------------------------------------

*   [大厂技术实现：推荐与广告计算解决方案](https://www.showmeai.tech/tutorials/50)
*   [大厂技术实现：计算机视觉解决方案](https://www.showmeai.tech/tutorials/51)
*   [大厂技术实现：自然语言处理行业解决方案](https://www.showmeai.tech/tutorials/52)
*   [图解Python编程：从入门到精通系列教程](https://www.showmeai.tech/tutorials/56)
*   [图解数据分析：从入门到精通系列教程](https://www.showmeai.tech/tutorials/33)
*   [图解AI数学基础：从入门到精通系列教程](https://www.showmeai.tech/tutorials/83)
*   [图解大数据技术：从入门到精通系列教程](https://www.showmeai.tech/tutorials/84)
*   [图解机器学习算法：从入门到精通系列教程](https://www.showmeai.tech/tutorials/34)
*   [机器学习实战：手把手教你玩转机器学习系列](https://www.showmeai.tech/tutorials/41)
*   [深度学习教程：吴恩达专项课程 · 全套笔记解读](https://www.showmeai.tech/tutorials/35)
*   [自然语言处理教程：斯坦福CS224n课程 · 课程带学与全套笔记解读](https://www.showmeai.tech/tutorials/36)